{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c02d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (997, 11)\n",
      "Test MSE: 7.0775\n",
      "Test R²: 0.5132\n",
      "✅ Pipeline saved to ../model/full_pipeline.pkl\n",
      "✅ Feature list saved to ../model/features.json\n",
      "Dropped 3 rows due to NaN/Inf/large values after cleaning.\n",
      "Deployment Data Test MSE: 31.1728\n",
      "Deployment Data Test R²: 0.9311\n",
      "✅ Predictions saved to ../data/results/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ### 1. Imports & Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs('../model', exist_ok=True)\n",
    "os.makedirs('../data/results', exist_ok=True)\n",
    "\n",
    "# %%\n",
    "# ### 2. Load Data and Define Features/Target\n",
    "\n",
    "df = pd.read_csv('../data/cleaned/feature_engineered_data.csv')\n",
    "\n",
    "features = ['price', '1h', '24h', '7d', '24h_volume', 'mkt_cap',\n",
    "            'price_ma7', 'price_ma30', 'volatility_7d', 'volume_change_pct', 'price_change_pct']\n",
    "target = 'liquidity_ratio'\n",
    "\n",
    "# Replace inf/-inf with NaN in features and target\n",
    "df[features] = df[features].replace([np.inf, -np.inf], np.nan)\n",
    "df[target] = df[target].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Clip extreme values to avoid overflow issues\n",
    "df[features] = df[features].clip(lower=-1e10, upper=1e10)\n",
    "df[target] = df[target].clip(lower=-1e10, upper=1e10)\n",
    "\n",
    "# Drop rows with any NaN in features or target\n",
    "df_clean = df.dropna(subset=features + [target])\n",
    "\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "print(f\"Data shape after cleaning: {X.shape}\")\n",
    "\n",
    "# %%\n",
    "# ### 3. Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# %%\n",
    "# ### 4. Define and Train Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        max_features=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=2,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# %%\n",
    "# ### 5. Evaluate on Test Set\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Safety check\n",
    "if np.any(np.isinf(y_pred)) or np.any(np.isnan(y_pred)):\n",
    "    raise ValueError(\"Predictions contain NaN or Inf\")\n",
    "if np.any(np.isinf(y_test)) or np.any(np.isnan(y_test)):\n",
    "    raise ValueError(\"Actual test values contain NaN or Inf\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "# %%\n",
    "# ### 6. Save Pipeline and Feature List\n",
    "\n",
    "joblib.dump(pipeline, '../model/full_pipeline.pkl')\n",
    "print(\"✅ Pipeline saved to ../model/full_pipeline.pkl\")\n",
    "\n",
    "with open('../model/features.json', 'w') as f:\n",
    "    json.dump(features, f)\n",
    "print(\"✅ Feature list saved to ../model/features.json\")\n",
    "\n",
    "# %%\n",
    "# ### 7. Prediction & Deployment Step (can be run separately later)\n",
    "\n",
    "pipeline = joblib.load('../model/full_pipeline.pkl')\n",
    "with open('../model/features.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "\n",
    "df_pred = pd.read_csv('../data/cleaned/feature_engineered_data.csv')\n",
    "\n",
    "# Replace inf/-inf with NaN in features\n",
    "df_pred[features] = df_pred[features].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Clip extreme values in features\n",
    "df_pred[features] = df_pred[features].clip(lower=-1e10, upper=1e10)\n",
    "\n",
    "# Drop rows with NaNs in features\n",
    "valid_idx = df_pred[features].dropna().index\n",
    "X_pred = df_pred.loc[valid_idx, features]\n",
    "\n",
    "# Clean target similarly\n",
    "df_pred.loc[valid_idx, target] = df_pred.loc[valid_idx, target].replace([np.inf, -np.inf], np.nan)\n",
    "df_pred.loc[valid_idx, target] = df_pred.loc[valid_idx, target].clip(lower=-1e10, upper=1e10)\n",
    "\n",
    "# Drop any rows with NaN in target after cleaning\n",
    "valid_idx_final = df_pred.loc[valid_idx, target].dropna().index\n",
    "\n",
    "X_pred = df_pred.loc[valid_idx_final, features]\n",
    "y_true = df_pred.loc[valid_idx_final, target]\n",
    "\n",
    "print(f\"Dropped {len(df_pred) - len(X_pred)} rows due to NaN/Inf/large values after cleaning.\")\n",
    "\n",
    "# Final sanity checks\n",
    "if np.isinf(X_pred.values).any() or np.isinf(y_true.values).any():\n",
    "    raise ValueError(\"Infinite values remain in features or target after cleaning!\")\n",
    "if (np.abs(X_pred.values) > 1e10).any() or (np.abs(y_true.values) > 1e10).any():\n",
    "    raise ValueError(\"Too large values remain in features or target after cleaning!\")\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_pred)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Deployment Data Test MSE: {mse:.4f}\")\n",
    "print(f\"Deployment Data Test R²: {r2:.4f}\")\n",
    "\n",
    "# Save predictions\n",
    "df_results = df_pred.loc[y_true.index].copy()\n",
    "df_results['predicted_liquidity_ratio'] = y_pred\n",
    "df_results.to_csv('../data/results/predictions.csv', index=False)\n",
    "print(\"✅ Predictions saved to ../data/results/predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe7118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\jashw\\Cryptocurrency Liquidity Prediction for Market Stability\\Notebook\n",
      "Loading data from ../data/cleaned/feature_engineered_data.csv\n",
      "Data loaded with columns: ['coin', 'symbol', 'price', '1h', '24h', '7d', '24h_volume', 'mkt_cap', 'date', 'SourceFile', 'price_ma7', 'price_ma30', 'volatility_7d', 'volume_change_pct', 'price_change_pct', 'liquidity_ratio', 'liquidity_ratio_7d']\n",
      "Features loaded: ['price', '1h', '24h', '7d', '24h_volume', 'mkt_cap', 'price_ma7', 'price_ma30', 'volatility_7d', 'volume_change_pct', 'price_change_pct']\n",
      "✅ Deployment CSV created at: ../Data/Cleaned/deployment_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Paths \n",
    "data_path = '../data/cleaned/feature_engineered_data.csv'\n",
    "features_path = '../model/features.json'\n",
    "deployment_csv_path = '../Data/Cleaned/deployment_data.csv'\n",
    "\n",
    "print(f\"Current working dir: {os.getcwd()}\")\n",
    "\n",
    "# Load dataframe\n",
    "print(f\"Loading data from {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Data loaded with columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Load features list\n",
    "if not os.path.exists(features_path):\n",
    "    raise FileNotFoundError(f\"Features JSON file not found at {features_path}\")\n",
    "\n",
    "with open(features_path, 'r') as f:\n",
    "    features = json.load(f)\n",
    "\n",
    "print(f\"Features loaded: {features}\")\n",
    "\n",
    "# Check for missing features\n",
    "missing_features = set(features) - set(df.columns)\n",
    "if missing_features:\n",
    "    print(f\"Warning: These features are missing in dataframe columns: {missing_features}\")\n",
    "\n",
    "# Filter dataframe with available features only\n",
    "filtered_features = [feat for feat in features if feat in df.columns]\n",
    "df_deployment = df[filtered_features]\n",
    "\n",
    "# Save deployment CSV\n",
    "os.makedirs(os.path.dirname(deployment_csv_path), exist_ok=True)\n",
    "df_deployment.to_csv(deployment_csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Deployment CSV created at: {deployment_csv_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
